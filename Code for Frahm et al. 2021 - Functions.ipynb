{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This script is for the statistical data analysis for the article \"Classification and biomarker identification of prostate tissue from TRAMP mice with hyperpolarized 13C-SIRA\" by A. Frahm et al. Talanta. 2021 Aug 20:122812.\n",
    "\n",
    "All code is written by A Frahm (annetirsdag@gmail.com).\n",
    "\n",
    "Versions used:\n",
    "\n",
    "Python: 3.6.10 Scipy: 1.5.2 sklearn: 0.23.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-02T08:30:26.997873Z",
     "start_time": "2021-10-02T08:30:25.026933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import winsound\n",
    "\n",
    "from collections import defaultdict #Used in RF for ordered dictionary\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict, cross_val_score, GridSearchCV,  StratifiedShuffleSplit\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "#set figuresize, some functions changes this\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "#set up colors for plots to use\n",
    "color_set = np.array([\"#990000\",\"steelblue\", 'indigo', 'lime', 'chocolate', 'navy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makepca(d, cat,  scale = \"s\"):    \n",
    "    \n",
    "    \"\"\"\n",
    "    Makes Principal Components Analysis (PCA) and plots score plot of 1. and 2. components. \n",
    "    Scales data first.\n",
    "    Prints out list of importance (in %) of all components.\n",
    "\n",
    "    Input:\n",
    "    d(n x m pd DataFrame): X-varaible; datamatrix with features as columns and datapoints as rows.\n",
    "    cat(n-lenght list-like): Y-variable; labels to color after\n",
    "    scale(string, \"s\", \"p\" or \"n\") :scaling method. \"s\" = standard(default). \"p\" = Pareto. \"n\" = No scaling.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #scale data set \"sf\" parameter that scales spectrum in loading plot\n",
    "    if scale == \"s\":\n",
    "        #autoscale\n",
    "        data =  (d - d.mean())/d.std()\n",
    "    elif scale == \"p\":\n",
    "        #paretoscale\n",
    "        data =  (d - d.mean())/d.std()**0.5\n",
    "    elif scale == \"n\":\n",
    "        #no scale\n",
    "        data = d\n",
    "    else:\n",
    "        #End function if no method chosen\n",
    "        raise Exception(\"No correct scale method specified: 'scale' has to be 's','p' or 'n'\")\n",
    "    \n",
    "    \n",
    "    #check if number of components have been chosen\n",
    "\n",
    "    #make PCA    \n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "    data_pc = pca.transform(data)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    \n",
    "    \n",
    "    #get classes as numbers\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(cat)\n",
    "    label_set = le.classes_\n",
    "    labels_data =le.transform(cat)\n",
    "        \n",
    "    \n",
    "    #Prepare colors corresponding to labels for plotting\n",
    "    colors = {}\n",
    "    for i in range(len(label_set)):\n",
    "        colors[label_set[i]] = color_set[i] #color_set has to be set outside of function\n",
    "    \n",
    "    types = len(label_set)\n",
    "    \n",
    "    #Plot PCA scores\n",
    "    for label in range(len(label_set)):\n",
    "        \n",
    "        c = colors[label_set[label]]\n",
    "        x = data_pc[:,0][labels_data == label]\n",
    "                \n",
    "        y=data_pc[:,1][labels_data == label]\n",
    "        \n",
    "        plt.scatter(x,y, color = c, label = label_set[label], s= 70)\n",
    "        \n",
    "    bob = \"PC1 %.2f%%\" %(pca.explained_variance_ratio_[0]*100)\n",
    "    plt.xlabel(bob, fontsize = 25)\n",
    "    bob = \"PC2 %.2f%%\" %(pca.explained_variance_ratio_[1]*100)\n",
    "    plt.ylabel(bob, fontsize = 25)\n",
    "    plt.title('PCA Scoreplot', fontsize = 25)\n",
    "    plt.legend( prop={'size': 25}, loc = 2)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.show()\n",
    "    \n",
    "    with np.printoptions(precision=3, suppress=True):\n",
    "        print(np.round(pca.explained_variance_ratio_*100, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:53:38.166427Z",
     "start_time": "2021-07-09T13:53:38.123457Z"
    }
   },
   "outputs": [],
   "source": [
    "def makerf(data, cat, trees = 600, loops = 10000, params = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function for making importance ranking of features with random forest classification.\n",
    "    Importance measured through shuffling values in each feature and comparing classifictaion success \n",
    "    between normal and shuffled data.\n",
    "    \n",
    "    Input:\n",
    "    data(dataframe, m x n): x-variable, data with features as columns and datapoints as rows.\n",
    "    cat(list-like, n): y-variable to classify after.\n",
    "    trees(optional) = n_estismaters for forest, default 600\n",
    "    loops(optional) = Number of repetitions for \n",
    "    params(dict)(optional): additional parameters for random forest if non-default to be used.\n",
    "    \n",
    "    Output:\n",
    "    imp(dataframe): Importance matrix with columns \"Mean\" and \"std err.\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #make sure we can handle Y in both array and Dataframe\n",
    "    if type(cat) == pd.Series:\n",
    "        cat = np.ravel(cat.values)\n",
    "    \n",
    "    #define Random Forest classifier and fit to all data\n",
    "    if params is None:\n",
    "        rf = RF(n_estimators= trees, oob_score= True)\n",
    "    else:\n",
    "        rf = RF(n_estimators= trees, oob_score= True, **params)\n",
    "    \n",
    "    rf.fit(data,cat)\n",
    "    \n",
    "    print(\"Out-of-bag score (%):\", rf.oob_score_*100)\n",
    "    \n",
    "    scores = defaultdict(list) #empty library for tracking scores\n",
    "\n",
    "    #define train-test splits, stratified to ensure all cell lines are in test\n",
    "    splits = StratifiedShuffleSplit(loops, train_size = 0.7)\n",
    "\n",
    "    #run test \n",
    "    for train_idx, test_idx in splits.split(data, cat):\n",
    "        \n",
    "        #sort training and testing\n",
    "        X_train = data.values[train_idx]\n",
    "        X_test = data.values[test_idx]\n",
    "        Y_train = cat[train_idx]\n",
    "        Y_test = cat[test_idx]\n",
    "    \n",
    "        #fit RF to training data\n",
    "        r = rf.fit(X_train, Y_train)\n",
    "        \n",
    "        #get true accuracy\n",
    "        acc = sum(rf.predict(X_test) == Y_test)/len(Y_test)\n",
    "    \n",
    "        #for each feature get difference in accuracy when test classes are shuffled\n",
    "        if acc > 0: #avoid divide by zero error, sometimes occurying with small dataset/randomized data\n",
    "            for i in range(len(data.columns)):\n",
    "                X_t = X_test.copy()\n",
    "                np.random.shuffle(X_t[:, i])\n",
    "                shuff_acc = sum(rf.predict(X_t) == Y_test)/len(Y_test)\n",
    "                scores[data.columns[i]].append((acc-shuff_acc)/acc)\n",
    "\n",
    "        \n",
    "    imp = pd.DataFrame(columns= ['Mean', 'std err.', 'color'])\n",
    "\n",
    "    #color code positive-negative\n",
    "    for feat in scores: \n",
    "        m = np.mean(scores[feat])\n",
    "        c = 'r'\n",
    "        if m > 0:\n",
    "            c = 'g'\n",
    "        imp.loc[feat] = [m, stats.sem(scores[feat]), c] \n",
    "        #stats.sem = standard error on the mean\n",
    "\n",
    "    imp=imp.sort_values('Mean', ascending = False)\n",
    "    \n",
    "    #plot important features, maximum 30\n",
    "    ml = min(len(imp), 30)\n",
    "    \n",
    "    imp.iloc[:ml].plot.bar(y = 'Mean', yerr = 'std err.', color = imp.color, legend = False)\n",
    "    plt.ylabel('Relative importance ')\n",
    "    plt.show()\n",
    "    return(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_clean(imp):\n",
    "    \"\"\" \n",
    "    Takes RF importance results and returns only significant features.\n",
    "    Significance cutoff set to be 5% of score of highest importance feature.\n",
    "    \n",
    "    Input:\n",
    "    imp(dataframe): Importance matrix with columns \"Mean\" and \"std err.\"\n",
    "    \n",
    "    Output:\n",
    "    imp_sig(array): Index values of features found to have significant positive importance.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cutoff = (imp.Mean.iloc[0] - imp['std err.'].iloc[0]) * 0.05\n",
    "    \n",
    "    imp_sig = imp[(imp.Mean - imp['std err.']) > cutoff]\n",
    "    \n",
    "    return(imp_sig.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rfs(imp_chart, ml):\n",
    "    \n",
    "    \"\"\"\n",
    "    Makes pretty plot of only the significantly important features.\n",
    "    \n",
    "    Input:\n",
    "    imp_chart(dataframe): Importance matrix with columns \"Mean\" and \"std err.\"\n",
    "    ml(array): List of features in imp_chart to be plotted\n",
    "    \"\"\"\n",
    "    \n",
    "    imps = imp_chart.loc[ml]\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    \n",
    "    imps.plot.bar(y = 'Mean', yerr = 'std err.', color = 'olivedrab', legend = False)\n",
    "    plt.title('RF feature importance', fontsize = 25)\n",
    "    plt.ylabel('Relative importance', fontsize = 25)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.xlabel('Chemical shift (ppm)', fontsize = 25)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:54:30.216680Z",
     "start_time": "2021-08-30T09:54:30.190627Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadings_pca(d, annotate = False, scale = \"s\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Makes Principal Components Analysis (PCA) and plots loading plot of 1. and 2. components, \n",
    "    for all features in the dataset. \n",
    "    Scales data first.\n",
    "\n",
    "    Input:\n",
    "    d(n x m pd DataFrame): X-varaible; datamatrix with features as columns and datapoints as rows.\n",
    "    annotate(default = False): Boolean, wheter to print feature names in plot. \n",
    "    scale(string, \"s\", \"p\" or \"n\") :scaling method. \"s\" = standard(default). \"p\" = Pareto. \"n\" = No scaling.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #scale data set \"sf\" parameter that scales spectrum in loading plot\n",
    "    if scale == \"s\":\n",
    "        #autoscale\n",
    "        data =  (d - d.mean())/d.std()\n",
    "    elif scale == \"p\":\n",
    "        #paretoscale\n",
    "        data =  (d - d.mean())/d.std()**0.5\n",
    "    elif scale == \"n\":\n",
    "        #no scale\n",
    "        data = d\n",
    "    else:\n",
    "        #End function if no method chosen\n",
    "        raise Exception(\"No correct scale method specified: 'scale' has to be 's','p' or 'n'\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #make PCA    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(data)\n",
    "    data_pc = pca.transform(data)        \n",
    "    \n",
    "    \n",
    "    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "    \n",
    "    #Plot PCA scores\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [10, 10]  \n",
    "    \n",
    "    for i, feature in enumerate(d.columns):\n",
    "        \n",
    "        x = loadings[i, 0]\n",
    "        y = loadings[i, 1]\n",
    "        \n",
    "        plt.plot([0, x], [0, y], 'k-', lw=2)\n",
    "        \n",
    "        if annotate == True:\n",
    "            plt.annotate(feature, (x, y), fontsize = 15)\n",
    "    \n",
    "    bob = \"PC1 %.2f%%\" %(pca.explained_variance_ratio_[0]*100)\n",
    "    plt.xlabel(bob, fontsize = 25)\n",
    "    bob = \"PC2 %.2f%%\" %(pca.explained_variance_ratio_[1]*100)\n",
    "    plt.ylabel(bob, fontsize = 25)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.title('PCA Loadings', fontsize = 25)\n",
    "    #plt.xlim([-0.25, 1])\n",
    "    #plt.ylim([-0.85, 0.41])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makesvm(d, cat, scale = \"s\", print_out = None):\n",
    "    \"\"\"\n",
    "    Function for making Support Vector Machine (svm) classification, using grid search to optimize internal parameters.\n",
    "    Data can be scaled before algoritm is run, different scaling methods can be chosen\n",
    "    Options for cost parameter (C) are 2^n with n being (-5:5). A linear kernel function is used.\n",
    "    \n",
    "    Input:\n",
    "    d(n x m pd DataFrame): X-varaible; datamatrix with features as columns and datapoints as rows.\n",
    "    cat(n-lenght list-like): Y-variable; labels to classify after\n",
    "    scale(string, \"s\", \"p\" or \"n\") :scaling method. \"s\" = standard(default). \"p\" = Pareto. \"n\" = No scaling.\n",
    "    print_out(bool): If not \"None\" stats on classification parameters and errors are printed on screen.\n",
    "    \n",
    "    Output:\n",
    "    grid(GridSearchCV object): Obtimizing algoritm fitted to the data. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #scale data\n",
    "    if scale == \"s\":\n",
    "        #Autoscale\n",
    "        data =  (d - d.mean())/d.std()\n",
    "    elif scale == \"p\":\n",
    "        #Pareto scale\n",
    "        data =  (d - d.mean())/d.std()**0.5\n",
    "    elif scale == \"n\":\n",
    "        #No scaling\n",
    "        data = d\n",
    "    else:\n",
    "        raise Exception(\"No correct scale method specified: 'scale' has to be 's','p' or 'n'\")\n",
    "    \n",
    "    #get classes as numbers\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(cat)\n",
    "    label_set = le.classes_ #list of classes\n",
    "    labels_data =le.transform(cat) #encoded y-variable\n",
    "    \n",
    "    #set up standard SVM\n",
    "    clf = svm.SVC(probability=True)\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    \n",
    "    #set up options for parameter grid\n",
    "    bob = np.arange(-5, 5, 1)\n",
    "    bub = np.ones(len(bob))*2\n",
    "    power2 = bub**bob\n",
    "    \n",
    "    #param_grid = [{'kernel': ['linear'], 'C': power2},{'kernel': ('rbf', 'poly'), 'C': power2,  'gamma': power2}]\n",
    "    param_grid = [{'kernel': ['linear'], 'C': power2}]    \n",
    "    \n",
    "    #set up gridsearch\n",
    "    grid = GridSearchCV(clf, param_grid, refit = True, cv= loo) \n",
    "  \n",
    "    # fitting the model for grid search \n",
    "    grid.fit(data, cat) \n",
    "    \n",
    "    #print some nice stats if wanted\n",
    "    if print_out is not None:\n",
    "        \n",
    "        #refit SVM classifier. If grid is used directly, predicted will be wrong.\n",
    "        clf = svm.SVC(**grid.best_params_, probability=True)\n",
    "        clf.fit(data, labels_data)\n",
    "        predicted_loo = cross_val_predict(clf, data, labels_data, cv= loo)\n",
    "                  \n",
    "        acc_loo = grid.best_score_ * 100\n",
    "        params = grid.best_params_\n",
    "        \n",
    "        #make confusion matrix\n",
    "        bub = np.array([label_set[s] for s in labels_data])\n",
    "        bob = np.array([label_set[s] for s in predicted_loo])\n",
    "        con_loo = pd.crosstab(bub, bob, rownames= [\"Actual\"], colnames= [\"predicted loo\"])\n",
    "        \n",
    "        #make list of errors \n",
    "        loo_pred_err = pd.DataFrame(np.column_stack([bub, bob]), columns = [\"Actual\", \"Predicted\"], index= d.index)\n",
    "        loo_pred_err = loo_pred_err[loo_pred_err.Actual != loo_pred_err.Predicted]\n",
    "        \n",
    "        print(\"Leave-One-Out validated classification score: \", acc_loo)\n",
    "        print(\"Parameters used: \", params)\n",
    "        print(\"Classification errors:\")\n",
    "        print(con_loo)\n",
    "        print(loo_pred_err)\n",
    "        \n",
    "    return(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_feats(data, cat, imp, scale = 's'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funtion for looping over makesvm() using more and more features in feature list(\"imp\").\n",
    "    \n",
    "    Input:\n",
    "    data(n x m pd DataFrame): X-varaible; datamatrix with features as columns and datapoints as rows.\n",
    "    cat(n-lenght list-like): Y-variable; labels to classify after\n",
    "    imp(array): list of significant features found in X, ranked from most important to least.\n",
    "    scale(string, \"s\", \"p\" or \"n\") :scaling method. \"s\" = standard(default). \"p\" = Pareto. \"n\" = No scaling.\n",
    "    Output:\n",
    "    svm_results(DataFrame): Classification succes rate of each feature set\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #tell user what scaling method they have chosen\n",
    "    if scale == 's':\n",
    "        print(\"Scaling method: Auto-scale\")\n",
    "    elif scale == 'p':\n",
    "        print(\"Scaling method: Pareto\")\n",
    "    elif scale == 'n':\n",
    "        print(\"Scaling method: None... Are you sure about this, champ?\")\n",
    "    else:\n",
    "        raise Exception(\"No correct scale method specified: 'scale' has to be 's','p' or 'n'\")\n",
    "    \n",
    "    svm_results = pd.DataFrame(columns= [\"score\", \"params\"]) \n",
    "    \n",
    "    #loop through feature list\n",
    "    for i in np.arange(len(imp)):\n",
    "        \n",
    "        #include features up to and with i\n",
    "        feat = imp[:i+1]\n",
    "        bob = makesvm(data[feat], cat, scale)\n",
    "        \n",
    "        #save stats\n",
    "        s_i = bob.best_score_\n",
    "        p_i = bob.best_params_\n",
    "        svm_results.loc[i+1] = [s_i, p_i]\n",
    "    \n",
    "    #once more with full featureset\n",
    "    bob = makesvm(data, cat, scale)\n",
    "    \n",
    "    s_i = bob.best_score_\n",
    "    p_i = bob.best_params_\n",
    "    svm_results.loc['Full'] = [s_i, p_i]\n",
    "    \n",
    "    return(svm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(d, bl = 0.02):\n",
    "    \"\"\"\n",
    "    Sums data into bins of uniform lenght and plots an overview of the binned data.\n",
    "    \n",
    "    Input:\n",
    "    d(DataFrame): Data to be strutured into bins, with ppm values, in decending order as column names.\n",
    "    bl(float): Length of the bins. Default is 0.02.\n",
    "    Output:\n",
    "    binned_d(DataFrame): d summed into bins, with columns named for lowest bin, roudend to three ciffers. \n",
    "    \n",
    "    \"\"\"\n",
    "    #make bins\n",
    "    bins = np.arange(d.columns.values[0], d.columns.values[-1], -bl)\n",
    "    \n",
    "    #define start of first bin\n",
    "    left = bins[0]\n",
    "    \n",
    "    #dataframe for output\n",
    "    binned_d = pd.DataFrame(index= data.index)\n",
    "    \n",
    "    #loop over all bins\n",
    "    for b in bins[1:]:\n",
    "        #columns in original data to inlcude in this bin\n",
    "        d_b = d[d.columns[(left >= d.columns) & (d.columns > b)]]\n",
    "        \n",
    "        #round bin name\n",
    "        b = np.round(b,3)\n",
    "        \n",
    "        #set sum of original data as values for this bin\n",
    "        binned_d[b] = d_b.sum(axis=1)\n",
    "        \n",
    "        #define start point of next bin\n",
    "        left = b\n",
    "    \n",
    "    print(\"There are %i bins in total\" %(len(binned_d.columns)))\n",
    "    \n",
    "    #make plot of binned data\n",
    "    plt.rcParams['figure.figsize'] = [40, 20]\n",
    "    \n",
    "    ax = binned_d.T.plot(legend= None)\n",
    "    xtick = bins[1:]\n",
    "    ax.set_xticks( xtick, minor=True )\n",
    "    ax.grid(True, which='minor', axis='x' ) #Show bins as grid\n",
    "    ax.grid(False, which='major', axis='x' ) #has to be False or extra grid lines, not showing bins\n",
    "    #couldn't get grid to show over numbers\n",
    "    \n",
    "    return(binned_d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
